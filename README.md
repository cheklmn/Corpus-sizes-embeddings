# Corpus-sizes-embeddings
The purpose of this project is to research the influence of corpora sizes and 
term frequencies on the accuracy of word embeddings trained on those corpora

## Introduction
In the application, the text from english Wikipedia corpus was used. 
The idea is to train models on corpus slices of different size as well as 

To determine the effect corpus size has on the word embedding, 

## Requirements
The project requires Python 2.7 and following packages to be installed:
* nltk
* gensim
* pandas
* tqdm
* matplotlib
* word-embedding benchmarks from https://github.com/kudkudak/word-embeddings-benchmarks

## Usage
Install packages from environment.ymd.
Configure project by editing global_params.py

## Results


## Next steps
* Move to Python 3
* Include analogy datasets for testing word frequencies
